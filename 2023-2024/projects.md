

# DataScience - IM-2023-2024


## Lectures

Week1: Opening :)

Week2: [Introduction]()

Week3: ML [review1](Examples/MLalgorithms.ipynb) [review2](Examples/MLopenCourse.ipynb)


## About projects

The project you have to do is an opportunity to explore an Artificial Intelligence (AI) problem in the context of real data. The project will be evaluated both at the end of the semester and during the semester, when each team will have to present to the teaching staff the completed application and the related technical report.


**AI Methods**

1. Federated learning
    - [link](https://federated.withgoogle.com/), 
    - [link](https://github.com/tensorflow/federated)

2. Semi-supervised learning.
    - [link](https://arxiv.org/pdf/2105.13502.pdf)

3. Graph-based learning
    - [link](https://github.com/pyg-team/pytorch_geometric)
    - [link](http://snap.stanford.edu/graphlearning-workshop/)

**Performance of the AI models**
1. Performance
    - qualitative (errors, accuracy, precision, IoU, Dice, etc.)
    - complexity (time, space/memory)
2. Explainability
    - [link](https://christophm.github.io/interpretable-ml-book/index.html)
    - [link](https://ema.drwhy.ai/preface.html)

Project steps:
- subject selection
- team (2-3 members)
- problem solving
- application development and AI integration
- documentation (report)
- final presentation


**Application development**
- using any programming language and technologies 
- codebases must be submitted [here](), before deadlines
- [good tips](https://www.deeplearningbook.org/)

**Technical report**
- must follows this template [link](Report/texModel/model.tex) and the recommended structure [link](Report/readme.md). 


**Final presentation**
- teaser (a short video presentation)
- slides (or other presentation support)


**Evaluation**
- [details](Eval/readme.md)


# Proposed topics

<details>
    <summary> 1. Uterine cervical cancer </summary>

### Aim
- automatic identification of lessions in MRI images of uterine cervical cancer.

### TODOlist
1. Problem definition (details about inputs and outputs)
2. Exploratory data analysis
3. AI development and performance evaluation 
4. Improvements

### Data
- dataset1 [link](https://synthrad2023.grand-challenge.org/)
- dataset2 [link](https://github.com/SynthRAD2023/preprocessing)

### Bibliografy
- Bourgioti, C., Chatoupis, K., & Moulopoulos, L. A. (2016). Current imaging strategies for the evaluation of uterine cervical cancer. World journal of radiology, 8(4), 342. [link](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4840192/)
- Zaki, N., Qin, W., & Krishnan, A. (2023). Graph-based methods for cervical cancer segmentation: Advancements, limitations, and future directions. AI Open. [link](https://www.sciencedirect.com/science/article/pii/S2666651023000086)
- Kurata, Y., Nishio, M., Moribata, Y., Kido, A., Himoto, Y., Otani, S., ... & Nakamoto, Y. (2021). Automatic segmentation of uterine endometrial cancer on multi-sequence MRI using a convolutional neural network. Scientific Reports, 11(1), 14440.[link](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8280152/#MOESM1)
- Lin, Y. C., Lin, Y., Huang, Y. L., Ho, C. Y., Chiang, H. J., Lu, H. Y., ... & Lin, G. (2023). Generalizable transfer learning of automated tumor segmentation from cervical cancers toward a universal model for uterine malignancies in diffusion-weighted MRI. Insights into Imaging, 14(1), 14. [link](https://insightsimaging.springeropen.com/articles/10.1186/s13244-022-01356-8)


</details>

<details>
    <summary> 2. Tracking - points of interest </summary>

### Aim 
- The study of the reaction of the muscles to certain stimuli by following the evolution of the contraction-relaxation movements in the images. The changes in the frames appear mainly as a result of a magnetic/electro-magnetic impulse that was intentionally generated by doctors.

### TODOlist
1. Problem definition (details about inputs and outputs)
2. Exploratory data analysis
3. AI development and performance evaluation 
4. Improvements

### Data
[link](https://ubbcluj.sharepoint.com/:v:/s/Proiect-Neuro-Spital-UBBMed-Tech/Ed9gAvkZi0JGjq6gHWr7cS8ByFY17SSQRCBfaOGVEC5fqA?e=y82ALb)

### Bibliografy

- Jung, I., Son, J., Baek, M., & Han, B. (2018). Real-time mdnet. In Proceedings of the European conference on computer vision (ECCV) (pp. 83-98) [link](https://openaccess.thecvf.com/content_ECCV_2018/papers/Ilchae_Jung_Real-Time_MDNet_ECCV_2018_paper.pdf)

- Wojke, N., Bewley, A., & Paulus, D. (2017, September). Simple online and realtime tracking with a deep association metric. In 2017 IEEE international conference on image processing (ICIP) (pp. 3645-3649). IEEE.[link](https://arxiv.org/abs/1703.07402)
- Object tracking [link](https://paperswithcode.com/task/object-tracking)
- Object tracking in OpenCV [link](https://pyimagesearch.com/2018/07/30/opencv-object-tracking/)
</details>

<details>
    <summary> 3. Detection of temporomandibular dysfunction </summary>

### Aim
- detection of temporomandibular dysfunction: detection of the temporomandibular disc, and if it is displaced anteriorly, laterally or medially.

### TODOlist
1. Problem definition (details about inputs and outputs)
2. Exploratory data analysis
3. AI development and performance evaluation 
4. Improvements

### Data
- dataset1 [link]()

### Bibliografy
- Li, M., Punithakumar, K., Major, P. W., Le, L. H., Nguyen, K. C. T., Pacheco-Pereira, C., ... & Almeida, F. T. (2022). Temporomandibular joint segmentation in MRI images using deep learning. Journal of Dentistry, 127, 104345. [link](https://www.sciencedirect.com/science/article/pii/S0300571222004006?casa_token=kP62C4pFphEAAAAA:5oZ7v2V0HoynVvs4vqnhTakWWK9_ld3JVMYKsonRTWo61tIQrkw8rlxFQES1PbsaSjHe_EeIWg#ack0001)
- Yoon, K., Kim, J. Y., Kim, S. J., Huh, J. K., Kim, J. W., & Choi, J. (2023). Explainable deep learning-based clinical decision support engine for MRI-based automated diagnosis of temporomandibular joint anterior disk displacement. Computer Methods and Programs in Biomedicine, 233, 107465. [link](https://www.sciencedirect.com/science/article/pii/S0169260723001311?casa_token=fdBVO7dvaOwAAAAA:KiIrANKeOvATQ-ilUzREjp0MxCJ8qOhe9VKmOBT9nEpB68GREx6_uZLpVtCPEOwUDpRY2qd5HA#sec0002)

</details>

<details>
    <summary> 4. Detection of cognitive distortions </summary>
### Aim
- The goal is to detect cognitive distortions in natural language text. This can be done by implementing and comparing different methods of binary classification of annotated data (obtained from patients) into categories such as: distorted and undistorted thinking. Moreover, the linguistic implications in the classification process can be analyzed (which characteristics of the text are more suitable for the detection of distortions: semantic or syntactic characteristics). 

### TODOlist
1. Problem definition (details about inputs and outputs)
2. Exploratory data analysis
3. AI development and performance evaluation 
4. Improvements

### Data
- Cognitive Distortion detetction dataset [link](https://www.kaggle.com/datasets/sagarikashreevastava/cognitive-distortion-detetction-dataset/data?select=Annotated_data.csv)

### Bibliografy
- Shreevastava, S., & Foltz, P. (2021, June). Detecting cognitive distortions from patient-therapist interactions. In Proceedings of the Seventh Workshop on Computational Linguistics and Clinical Psychology: Improving Access (pp. 151-158). [link](https://aclanthology.org/2021.clpsych-1.17.pdf)
- Wang, B., Deng, P., Zhao, Y., & Qin, B. (2023, December). C2D2 Dataset: A Resource for the Cognitive Distortion Analysis and Its Impact on Mental Health. In The 2023 Conference on Empirical Methods in Natural Language Processing. [link](https://openreview.net/pdf?id=NO5dc8Ljvj)
- Alhaj, F., Al-Haj, A., Sharieh, A., & Jabri, R. (2022). Improving Arabic cognitive distortion classification in Twitter using BERTopic. International Journal of Advanced Computer Science and Applications, 13(1), 854-860. [link](https://oars.uos.ac.uk/2327/1/Paper_99-Improving_Arabic_Cognitive_Distortion_Classification_in_Twitter.pdf)
- Hua, Y., Liu, F., Yang, K., Li, Z., Sheu, Y. H., Zhou, P., ... & Beam, A. (2024). Large Language Models in Mental Health Care: a Scoping Review. arXiv preprint arXiv:2401.02984. [link](https://arxiv.org/pdf/2401.02984.pdf)

</details>

