{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "version": "3.7.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.2 64-bit"
  },
  "interpreter": {
   "hash": "b15e34aad66e9e3b527f162cfcae96454e420cf4f38bc5947ead173934d3535a"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ML algorithms - Performance evaluation\n",
    "\n",
    "## Learning objectives\n",
    "* understanding the metrics used for regression problems and for classification problems\n",
    "\n",
    "## Ker terms:\n",
    "* prediction error \n",
    "* accuracy\n",
    "* precision\n",
    "* recall\n",
    "* confusion matrix\n",
    "\n",
    "# Requirements \n",
    "* compute the prediction performance in the case of a regression problem\n",
    "* compute the prediction performance in the case of a binary classification problem (balanced dataset and unbalanced dataset)\n",
    "* compute the prediction performance in the case of a binary classification problem (when the computed outputs are represented as probabilities - a $noSamples \\times noClasses$ values)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regression problems\n",
    "In a regression problem, the outputs of a prediction algorithm are represented by real values. \n",
    "For instance, we want to estimate the icecream consumption (in a camp) according to the temperature and the number of children in a camp.\n",
    "\n",
    "Suppose that an ML algorithm has provided, for a set of camps (known as set of inputs or set of samples), a set of icecream consumption (known as set of outputs) $computedOutputs$. The real icecream consumption are also known ($realOutputs$). Determine the algorithm's performance.\n",
    "\n",
    "A possible performance measure is given by the prediction error expressed as sum of the distances between the real outputs and the predicted outputs. The distance, for each sample, can be measured as:\n",
    "* the absolute difference  (this is $L_1$ distance):\n",
    "$$Error = \\sum_{i=1}^{noSamples} |realOutputs_i - computedOutputs_i|$$\n",
    "* the square difference (this is the $L_2$ distance):\n",
    "$$Error = \\sum_{i=1}^{noSamples} (realOutputs_i- computedOutputs_i) ^ 2$$ \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# consider some real values and some predicted values (obtained by the ML algorithm)\r\n",
    "\r\n",
    "realOutputs =     [3, 9.5, 4,   5.1, 6, 7.2, 2, 1]\r\n",
    "computedOutputs = [2, 7,   4.5, 6,   3, 8,   3, 1.2]\r\n",
    "\r\n",
    "# plot the data\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "indexes = [i for i in range(len(realOutputs))]\r\n",
    "real, = plt.plot(indexes, realOutputs, 'ro', label = 'real')\r\n",
    "computed, = plt.plot(indexes, computedOutputs, 'bo', label = 'computed')\r\n",
    "plt.xlim(0,8)\r\n",
    "plt.ylim(0, 10)\r\n",
    "plt.legend([real, (real, computed)], [\"Real\", \"Computed\"])\r\n",
    "plt.show()\r\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# compute the prediction error\r\n",
    "from math import sqrt\r\n",
    "\r\n",
    "errorL1 = sum(abs(r - c) for r, c in zip(realOutputs, computedOutputs))\r\n",
    "print('Error (L1): ', errorL1)\r\n",
    "\r\n",
    "errorL2 = sqrt(sum((r - c) ** 2 for r, c in zip(realOutputs, computedOutputs)))\r\n",
    "print('Error (L2): ', errorL2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error (L1):  9.899999999999999\n",
      "Error (L2):  4.357751713900186\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification problems\n",
    "If we deal by a binary classification problem, the outputs represent some labels. There are possible two labels, only (one for each class or output type). Suppose that class 1 is the positive class, while class 2 is the negative class. For instance, if we want to classify the emails into spam or ham messages, *spam* and *ham* are the two classes.\n",
    "\n",
    "An ML algorithm has provided, for a set of emails (known as set of inputs or set of samples), a set of spam/ham labels (known as set of outputs) $computedOutputs$. The real labels are also known $realOutputs$. Determine the algorithm's performance. \n",
    "\n",
    "Three performance measures are usefull for a classification problem: accuracy, precision, recall. Some pre-computations, enclosed in the confusion matrix are useful: \n",
    "* true positive \n",
    "* false positive\n",
    "* true negative\n",
    "* false negative\n",
    "\n",
    "The confusion matrix has the form: <img src=\"images/cm.png\" width=\"200\">\n",
    "* accuracy represents the overall performance of classification model: \n",
    "$$acc = \\frac{TP + TN}{TP + TN + FP + FN} = \\frac{correc predicted}{no of all samples}$$\n",
    "* precision indicates how accurate the positive predictions are: \n",
    "$$precision = \\frac{TP}{TP+FP}$$\n",
    "* recall indicates the coverage of actual positive sample: \n",
    "$$recall = \\frac{TP}{TP+FN}$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# a balanced data set (each class containes the same numer of samples)\r\n",
    "\r\n",
    "realLabels =        ['spam', 'spam', 'ham', 'ham', 'spam', 'ham']\r\n",
    "computedLabels =    ['spam', 'ham', 'ham', 'spam', 'spam', 'ham']\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# suppose that 'spam' is the positive class (and 'ham' is the negative class)\r\n",
    "# compute the prediction performance\r\n",
    "\r\n",
    "# version 1 - using the sklearn functions\r\n",
    "def evalClassificationV1(realLabels, computedLabels, labelNames):\r\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\r\n",
    "\r\n",
    "    cm = confusion_matrix(realLabels, computedLabels, labels = labelNames)\r\n",
    "    acc = accuracy_score(realLabels, computedLabels)\r\n",
    "    precision = precision_score(realLabels, computedLabels, average = None, labels = labelNames)\r\n",
    "    recall = recall_score(realLabels, computedLabels, average = None, labels = labelNames)\r\n",
    "    return acc, precision, recall \r\n",
    "\r\n",
    "# version 2 - native code\r\n",
    "def evalClassificationV2(realLabels, computedLabels, pos, neg):\r\n",
    "    # noCorrect = 0\r\n",
    "    # for i in range(0, len(realLabels)):\r\n",
    "    #     if (realLabels[i] == computedLabels[i]):\r\n",
    "    #         noCorrect += 1\r\n",
    "    # acc = noCorrect / len(realLabels)\r\n",
    "    acc = sum([1 if realLabels[i] == computedLabels[i] else 0 for i in range(0, len(realLabels))]) / len(realLabels)\r\n",
    "\r\n",
    "    # TP = 0\r\n",
    "    # for i in range(0, len(realLabels)):\r\n",
    "    #     if (realLabels[i] == 'spam' and computedLabels[i] == 'spam'):\r\n",
    "    #         TP += 1\r\n",
    "    TP = sum([1 if (realLabels[i] == pos and computedLabels[i] == pos) else 0 for i in range(len(realLabels))])\r\n",
    "    FP = sum([1 if (realLabels[i] == neg and computedLabels[i] == pos) else 0  for i in range(len(realLabels))])\r\n",
    "    TN = sum([1 if (realLabels[i] == neg and computedLabels[i] == neg) else 0 for i in range(len(realLabels))])\r\n",
    "    FN = sum([1 if (realLabels[i] == pos and computedLabels[i] == neg) else 0  for i in range(len(realLabels))])\r\n",
    "\r\n",
    "    precisionPos = TP / (TP + FP)\r\n",
    "    recallPos = TP / (TP + FN)\r\n",
    "    precisionNeg = TN / (TN + FN)\r\n",
    "    recallNeg = TN / (TN + FP)\r\n",
    "\r\n",
    "    return acc, precisionPos, precisionNeg, recallPos, recallNeg\r\n",
    "    \r\n",
    "acc, prec, recall = evalClassificationV1(realLabels, computedLabels, ['spam', 'ham'])\r\n",
    "\r\n",
    "# # # acc, prec, recall = evalClassificationV2(realLabels, computedLabels, 'spam', 'ham')\r\n",
    "\r\n",
    "# # print('acc: ', acc, ' precision: ', prec, ' recall: ', recall)\r\n",
    "\r\n",
    "\r\n",
    "# realLabels =        ['spam', 'spam', 'spam', 'spam', 'spam', 'spam']\r\n",
    "# computedLabels =    ['spam', 'ham', 'ham', 'spam', 'spam', 'new']\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# acc, prec, recall = evalClassificationV1(realLabels, computedLabels, ['spam', 'ham', 'new'])\r\n",
    "\r\n",
    "# # acc, prec, recall = evalClassificationV2(realLabels, computedLabels, 'spam', 'ham')\r\n",
    "\r\n",
    "print('acc: ', acc, ' precision: ', prec, ' recall: ', recall)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "acc:  0.6666666666666666  precision:  [0.66666667 0.66666667]  recall:  [0.66666667 0.66666667]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# an unbalanced data set (the numer of samples from each class are not uniform distributed)\r\n",
    "\r\n",
    "realLabels =        ['infected', 'infected', 'infected', 'infected', 'normal', 'normal', 'normal', 'normal', 'normal','normal', 'normal', 'normal', 'normal', 'normal', 'normal']\r\n",
    "computedLabels =    ['infected', 'infected', 'normal', 'normal', 'normal', 'normal','normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'normal', 'infected']\r\n",
    "\r\n",
    "acc, prec, recall = evalClassificationV1(realLabels, computedLabels, ['infected', 'normal'])\r\n",
    "# acc, prec, recall = evalClassificationV2(realLabels, computedLabels, 'infected', 'normal')\r\n",
    "\r\n",
    "print('acc: ', acc, ' precision: ', prec, ' recall: ', recall)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "acc:  0.8  precision:  [0.66666667 0.83333333]  recall:  [0.5        0.90909091]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification and probabilities\n",
    "\n",
    "What happens if the classification algorithm's **outputs represents probabilities**\n",
    "\n",
    "In this case, for each sample, $noClasses$ probabilities are computed (such as the summ of probabilities for a sample is 1). Remember that in the case of a binary classification problems ($noClasses$ = 2)\n",
    "\n",
    "$computedOutputs = [(p_{11}, p_{12}), (p_{21}, p_{22}), ..., (p_{n1}, p_{n2})]$\n",
    "\n",
    "where $p_{ij}$ is the probability that the sample $i$ belongs to class $j$ and $n$ is the number of samples\n",
    "\n",
    "The corresponding label is indicated by the largest probability\n",
    "\n",
    "$computedLabels = [argmax(p_{1j}), argmax(p_{2j}), ..., argmax(p_{nj}),$ where $j \\in \\{1, 2, .., noClasses\\}$\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# if the rawOutputs of the ML algorithms are probabilities (not labels)\r\n",
    "realLabels =        ['spam', 'spam', 'ham', 'ham', 'spam', 'ham']\r\n",
    "computedOutputs = [ [0.7, 0.3], [0.2, 0.8], [0.4, 0.6], [0.9, 0.1], [0.7, 0.3], [0.4, 0.6]]\r\n",
    "# computedLabels have to be  ['spam', 'ham', 'ham', 'spam', 'spam', 'ham']\r\n",
    "\r\n",
    "# transform the raw outputs into labels\r\n",
    "\r\n",
    "# version 1 - native code\r\n",
    "computedLabels = []\r\n",
    "labelNames = list(set(realLabels))\r\n",
    "for p in computedOutputs:\r\n",
    "    probMaxPos = p.index(max(p))\r\n",
    "    label = labelNames[probMaxPos]\r\n",
    "    computedLabels.append(label)\r\n",
    "\r\n",
    "# version 2 - by using NumPy library\r\n",
    "# import numpy as np\r\n",
    "# labelNames = list(set(realLabels))\r\n",
    "# computedLabels = [labelNames[np.argmax(p)] for p in computedOutputs]\r\n",
    "\r\n",
    "# compute the performance\r\n",
    "acc, prec, recall = evalClassificationV1(realLabels, computedLabels, ['spam', 'ham'])\r\n",
    "\r\n",
    "print('acc: ', acc, ' precision: ', prec, ' recall: ', recall)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "acc:  0.6666666666666666  precision:  [0.66666667 0.66666667]  recall:  [0.66666667 0.66666667]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Homework\n",
    "* compute the error in the case of a multi-target regression problem\n",
    "* compute the accuracy, precision, recall for a multi-class classification problem (computedOutputs are predicted labels)\n",
    "\n",
    "# Optional Homework\n",
    "* compute the loss in the case of a binary-classification problem (computed outputs are class probabilities - a matrix of $noSamples \\times noClasses$ real values, each line having sum 1)\n",
    "* compute the loss in the case of a multi-class classification problem (computed outputs are $noClasses$ real values)\n",
    "* compute the loss in the case of a multi-label classification problem (computed outputs are $noClasses$ real values)"
   ],
   "metadata": {}
  }
 ]
}